{
    "source_document": "output_results/resized_images/a_map_page_23_fitz_resized.png",
    "source_page_number": 0,
    "processing_timestamp_utc": "2025-11-25T04:32:32.147457+00:00",
    "status": "Layout extraction successful (Docker Inference)",
    "content": [
        {
            "extraction_id": 0,
            "metadata": {
                "source_page": 0,
                "type": "Page-header",
                "bbox": {
                    "xmin": 0.1416,
                    "ymin": 0.0492,
                    "xmax": 0.8379,
                    "ymax": 0.0578
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "Bao et al. Page 23"
            }
        },
        {
            "extraction_id": 1,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.2539,
                    "ymin": 0.0797,
                    "xmax": 0.835,
                    "ymax": 0.4461
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "image set shown in (**b**). However, PC2 no longer clearly corresponds to an animate- inanimate axis; instead, it corresponds to curved versus rectilinear shapes. **e.** Distributions showing the canonical correlation value between the first two PCs obtained by the 1224 image set and first two PCs built by other sets of images (1224 randomly selected non- background object images, left: PC1, right: PC2; see Methods for details). The red triangles indicate the average of the distributions. **f.** 19,300 object images were passed through AlexNet and PC1-PC2 space was built with PCA. Then we projected 1224 images on this PC1-PC2 space. The top 100 images for each network are indicated by colored dots (compare Fig. 4b). (**g**) Decoding accuracy for 40 images using object spaces built by responses of different layers of AlexNet (computed as in Extended Data Fig. 11d). There are multiple points for each layer because we performed PCA before and after pooling, activation, and normalization functions. Layer fc6 showed highest decoding accuracy, motivating our use of the object space generated by this layer throughout the paper. **h.** To compare IT clustering determined by AlexNet with that by other deep network architectures, we first determined the layer of each network giving best decoding accuracy, as in (g). The bar plot shows decoding accuracy for 40 images in the 9 different networks using the best- performing layer for each network. **i.** Canonical correlation values between the first two PCs obtained by Alexnet and first two PCs built by 8 other deep-learning networks (labelled as 2-9). The layer of each network yielding highest decoding accuracy for 40 images was used for this analysis. The name of each network and layer name can be found in (**j**). **j.** Same as Fig. 4b using PC1 and PC2 computed from 8 other networks."
            }
        },
        {
            "extraction_id": 2,
            "metadata": {
                "source_page": 0,
                "type": "Page-footer",
                "bbox": {
                    "xmin": 0.3066,
                    "ymin": 0.9031,
                    "xmax": 0.6064,
                    "ymax": 0.9125
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "_Nature._ Author manuscript; available in PMC 2021 May 01."
            }
        },
        {
            "extraction_id": 3,
            "metadata": {
                "source_page": 0,
                "type": "Caption",
                "bbox": {
                    "xmin": 0.0488,
                    "ymin": 0.0961,
                    "xmax": 0.0674,
                    "ymax": 0.2258
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "Author Manuscript"
            }
        },
        {
            "extraction_id": 4,
            "metadata": {
                "source_page": 0,
                "type": "Caption",
                "bbox": {
                    "xmin": 0.0498,
                    "ymin": 0.3094,
                    "xmax": 0.0674,
                    "ymax": 0.432
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "Author Manuscript"
            }
        },
        {
            "extraction_id": 5,
            "metadata": {
                "source_page": 0,
                "type": "Caption",
                "bbox": {
                    "xmin": 0.0508,
                    "ymin": 0.5227,
                    "xmax": 0.0674,
                    "ymax": 0.6453
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "Author Manuscript"
            }
        },
        {
            "extraction_id": 6,
            "metadata": {
                "source_page": 0,
                "type": "Caption",
                "bbox": {
                    "xmin": 0.0498,
                    "ymin": 0.7359,
                    "xmax": 0.0684,
                    "ymax": 0.8586
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "Author Manuscript"
            }
        }
    ]
}